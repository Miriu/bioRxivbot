{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, timedelta\n",
    "import sqlite3\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'status': 'ok', 'interval': '2020-11-19:2020-11-19', 'cursor': 0, 'count': 100, 'count_new_papers': 75, 'total': 114}]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "def get_papers():\n",
    "    today = date.today()\n",
    "    yesterday = today - timedelta(days = 1)\n",
    "    papers = requests.get(\"https://api.biorxiv.org/details/biorxiv/\" + str(yesterday) + \"/\" + str(yesterday))\n",
    "    papers_dic = papers.json()\n",
    "    connection = sqlite3.connect('tweetbot.db')\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute('''DROP TABLE if exists yesterday_pubs''')\n",
    "    cursor.execute('''CREATE TABLE 'yesterday_pubs'\n",
    "                        ('doi', 'title','authors', 'author_corresponding', \n",
    "                      'author_corresponding_institution', 'date', \n",
    "                      'version', 'type','license','category','abstract','published','server')''')\n",
    "    for child in papers_dic['collection']:\n",
    "        cursor.execute('INSERT INTO yesterday_pubs VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?)', \n",
    "                      (child['doi'], child['title'], child['authors'], child['author_corresponding'], \n",
    "                      child['author_corresponding_institution'], child['date'], \n",
    "                      child['version'], child['type'], child['license'], \n",
    "                        child['category'],child['abstract'],child['published'],child['server']))\n",
    "    connection.commit()\n",
    "    pap = papers_dic['messages']\n",
    "    print(pap)\n",
    "    pepe = pap[0]\n",
    "    for key,value in pepe.items():\n",
    "        if key == 'total':\n",
    "            n_papers =  value\n",
    "    if n_papers > 100:\n",
    "        total_loops = math.floor(n_papers/100)\n",
    "        start = 101\n",
    "        for n in range(total_loops):\n",
    "            papers = requests.get(\"https://api.biorxiv.org/details/biorxiv/\" + str(yesterday) + \"/\" + str(yesterday) + '/' + str(start))\n",
    "            start += 100\n",
    "            papers_dic = papers.json()\n",
    "            connection = sqlite3.connect('tweetbot.db')\n",
    "            cursor = connection.cursor()\n",
    "            for child in papers_dic['collection']:\n",
    "                cursor.execute('INSERT INTO yesterday_pubs VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?)', \n",
    "                              (child['doi'], child['title'], child['authors'], child['author_corresponding'], \n",
    "                              child['author_corresponding_institution'], child['date'], \n",
    "                              child['version'], child['type'], child['license'], \n",
    "                                child['category'],child['abstract'],child['published'],child['server']))\n",
    "            connection.commit()\n",
    "            start += 100\n",
    "        print('ok')\n",
    "    \n",
    "get_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"(abstract LIKE '%pluripotent stem cells%' OR abstract LIKE '%embryonic stem cells%') AND (abstract LIKE '%cardiomyocytes%' OR abstract LIKE '%cardio*%' OR abstract LIKE '%cardiac differentiation%')\",\n",
       " \"(abstract LIKE '%pluripotent stem cells%' OR abstract LIKE '%embryonic stem cells%') AND (abstract LIKE '%microRNA%' OR abstract LIKE '%miRNA%' OR abstract LIKE '%lncRNA or lon-non-codingRNA or non-coding RNA%' OR abstract LIKE '%circRNA%')\",\n",
       " \"(abstract LIKE '%pluripotent stem cells%' OR abstract LIKE '%embryonic stem cells%') AND (abstract LIKE '%microfluidics%')\",\n",
       " \"(abstract LIKE '%pluripotent stem cells%' OR abstract LIKE '%embryonic stem cells%') AND (abstract LIKE '%gastrulation%' OR abstract LIKE '%tbx6%' OR abstract LIKE '%oct-6%' OR abstract LIKE '%oct6%')\",\n",
       " \"abstract LIKE '%C19MC%' OR abstract LIKE '%Chromosome 19 microRNA cluster%' OR abstract LIKE '%Chromosome 19 miRNA cluster%'\",\n",
       " \"abstract LIKE '%pluripotent stem cells%' OR abstract LIKE '%embryonic stem cell%'\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_keywords():\n",
    "    regex_list = []\n",
    "    with open('search.txt') as f:\n",
    "        lines = [i.strip() for i in f.readlines()]\n",
    "        lowline = []\n",
    "        for line in lines:\n",
    "            if ') AND (' in line:\n",
    "                prelowline = line.replace(') AND (', ' XXXX ')\n",
    "                prelowline = prelowline.replace('(', '(abstract LIKE \\'%').replace(')', '%\\')').replace(' OR ', '%\\' OR abstract LIKE \\'%').replace(' AND ', '%\\' AND abstract LIKE \\'%')\n",
    "                prelowline = prelowline.replace(' XXXX ', '%\\') AND (abstract LIKE \\'%')\n",
    "                lowline.append(prelowline)\n",
    "            elif ') OR (' in line:\n",
    "                prelowline = line.replace(') OR (', ' XXXX ')\n",
    "                prelowline = prelowline.replace('(', '(abstract LIKE \\'%').replace(')', '%\\')').replace(' OR ', '%\\' OR abstract LIKE \\'%').replace(' AND ', '%\\' AND abstract LIKE \\'%')\n",
    "                prelowline = prelowline.replace(' XXXX ', '%\\') OR (abstract LIKE \\'%')\n",
    "                lowline.append(prelowline)\n",
    "            else:\n",
    "                prelowline = line.replace(' OR ', '%\\' OR abstract LIKE \\'%').replace(' AND ', '%\\' AND abstract LIKE \\'%')\n",
    "                prelowline = 'abstract LIKE \\'%' + prelowline + '%\\''\n",
    "                lowline.append(prelowline)\n",
    "        return lowline\n",
    "\n",
    "load_keywords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10.1101/2020.11.19.389445',\n",
       "  'Ngn2 induces diverse neuronal lineages from human pluripotency',\n",
       "  '1'),\n",
       " ('10.1101/2020.11.17.386839',\n",
       "  'Signatures Of TSPAN8 Variants Associated With Human Metabolic Regulation And Diseases',\n",
       "  '1')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_from_database():\n",
    "    connection = sqlite3.connect('tweetbot.db')\n",
    "    cursor = connection.cursor()\n",
    "    keywords = load_keywords()\n",
    "    for k in keywords:\n",
    "        sql = \"SELECT doi,title,version FROM yesterday_pubs WHERE \" + k + 'COLLATE NOCASE'\n",
    "        cursor.execute(sql)\n",
    "        retrived = cursor.fetchall()\n",
    "    return retrived\n",
    "        \n",
    "        \n",
    "read_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngn2 induces diverse neuronal lineages from human pluripotency\n",
      "Ngn2 induces diverse neuronal lineages from human pluripotency\n",
      "https://www.biorxiv.org/content/10.1101/2020.11.19.389445v1\n",
      "121\n",
      "Signatures Of TSPAN8 Variants Associated With Human Metabolic Regulation And Diseases\n",
      "Signatures Of TSPAN8 Variants Associated With Human Metabolic Regulation And ...\n",
      "https://www.biorxiv.org/content/10.1101/2020.11.17.386839v1\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "def search_and_tweet():\n",
    "    now = read_from_database()\n",
    "    for line in now:\n",
    "        doi = line[0]\n",
    "        title = line[1]\n",
    "        version = line[2]\n",
    "        link = \"https://www.biorxiv.org/content/\" + doi +'v' + version\n",
    "        print(title)\n",
    "        n_char = len(title) + len(link)\n",
    "        if n_char > 139:\n",
    "            max_title_length = 136 - len(link)\n",
    "            _title = title[:max_title_length]\n",
    "            final_title = _title + '...'\n",
    "        else:\n",
    "            final_title = title\n",
    "        print(final_title)\n",
    "        print(link)\n",
    "        print(len(final_title)+(len(link)))\n",
    "\n",
    "search_and_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngn2 induces diverse neuronal lineages from human pluripotency\n",
      "https://www.biorxiv.org/content/10.1101/2020.11.19.389445v1\n",
      "Signatures Of TSPAN8 Variants Associated With Human Metabolic Regulation And ...\n",
      "https://www.biorxiv.org/content/10.1101/2020.11.17.386839v1\n"
     ]
    }
   ],
   "source": [
    "def tweet():\n",
    "    now = read_from_database()\n",
    "    for line in now:\n",
    "        #for d in line:\n",
    "        doi = line[0]\n",
    "        title = line[1]\n",
    "        version = line[2]\n",
    "        link = \"https://www.biorxiv.org/content/\" + doi +'v' + version\n",
    "        n_char = len(title) + len(link)\n",
    "        if n_char > 139:\n",
    "            max_title_length = 136 - len(link)\n",
    "            _title = title[:max_title_length]\n",
    "            final_title = _title + '...'\n",
    "        else:\n",
    "            final_title = title\n",
    "\n",
    "        print(final_title)\n",
    "        print(\"https://www.biorxiv.org/content/\" + doi +'v' + version)\n",
    "        \n",
    "        \n",
    "tweet()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1Wwp27ydWI2wEk7lZLQQ3h0RB', 'AHKe1QK4tGl0MLSYUz4LLEFkQxCrhwFabQIzcEmDEsUPT7fzk3', '1329555337427492864-t7JjutO5tC6Gdo2k0NSjFMNn2pIiWe', 'Uv31B52v6Fnf8BwhFmrzePxBejORIWKmk0HFwi9wA30tX']\n",
      "<tweepy.auth.OAuthHandler object at 0x7fcb7ef4ca10>\n",
      "Authentication OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7fcb7ef4ea90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "def tweet_login():\n",
    "    creds = []\n",
    "    with open('credentials.txt') as f:\n",
    "        creds = [i.strip() for i in f.readlines()]\n",
    "        print(creds)\n",
    "        auth = tweepy.OAuthHandler(creds[0], creds[1])\n",
    "        print(auth)\n",
    "        auth.set_access_token(creds[2], creds[3])\n",
    "        api = tweepy.API(auth)\n",
    "        try:\n",
    "            api.verify_credentials()\n",
    "            print(\"Authentication OK\")\n",
    "        except:\n",
    "            print(\"Error during authentication\")\n",
    "        return api\n",
    "                \n",
    "tweet_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet(title, link):\n",
    "     api = tweet_login()\n",
    "     api.update_status(title, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'status': 'ok', 'interval': '2020-11-19:2020-11-19', 'cursor': 0, 'count': 100, 'count_new_papers': 75, 'total': 114}]\n",
      "ok\n",
      "['1Wwp27ydWI2wEk7lZLQQ3h0RB', 'AHKe1QK4tGl0MLSYUz4LLEFkQxCrhwFabQIzcEmDEsUPT7fzk3', '1329555337427492864-t7JjutO5tC6Gdo2k0NSjFMNn2pIiWe', 'Uv31B52v6Fnf8BwhFmrzePxBejORIWKmk0HFwi9wA30tX']\n",
      "<tweepy.auth.OAuthHandler object at 0x7fcb7ef61cd0>\n",
      "Authentication OK\n",
      "10.1101/2020.11.19.389445\n",
      "10.1101/2020.11.17.386839\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_and_tweet():\n",
    "    get_papers()\n",
    "    now = read_from_database()\n",
    "    api = tweet_login()\n",
    "    for line in now:\n",
    "        doi = line[0]\n",
    "        print(doi)\n",
    "        title = line[1]\n",
    "        version = line[2]\n",
    "        link = \"https://www.biorxiv.org/content/\" + doi +'v' + version\n",
    "        n_char = len(title) + len(link)\n",
    "        if n_char > 139:\n",
    "            max_title_length = 106 - len(link)\n",
    "            _title = title[:max_title_length]\n",
    "            final_title = _title + '...'\n",
    "        else:\n",
    "            final_title = title\n",
    "        with open('temp.txt', 'w') as f:\n",
    "            f.write(final_title + '\\n' + link)\n",
    "        with open('temp.txt', 'r') as f:\n",
    "            api.update_status(f.read())\n",
    "            f.close()\n",
    "        time.sleep(1)\n",
    "        \n",
    "search_and_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetbot",
   "language": "python",
   "name": "tweetbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
